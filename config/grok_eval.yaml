# Grok (xAI) Evaluation Configuration

model:
  provider: grok
  model_name: grok-beta
  temperature: 0.7
  max_tokens: 2000
  api_key_env: GROK_API_KEY

# Judge model for safety/quality evaluation
judge_model: claude-3-5-sonnet-20241022
judge_provider: anthropic

# Dataset configuration
golden_dataset_path: data/golden_dataset.json

# Output configuration
output_dir: ./eval_results/grok_beta

# LangSmith configuration
langsmith_project: medical-diagnosis-eval-grok
langsmith_api_key_env: LANGSMITH_API_KEY

# Metric thresholds
min_accuracy: 0.75
min_faithfulness: 0.80
min_safety_score: 4.0
max_cost_per_query: 0.10
max_p95_latency: 3000.0

# Evaluation options
subset_size: null  # null = evaluate all cases
verbose: false
